# 혼자서 10개 AI 에이전트, 6개 파이프라인, 16개 채널을 만든 이야기

## Claude Code와 함께한 멀티 에이전트 콘텐츠 플랫폼 개발기

---

나는 콘텐츠를 만드는 사람이다. Medium에 글을 쓰고, LinkedIn에 인사이트를 올리고, YouTube에 영상을 올린다. 가끔 X에 스레드도 쓰고, 인스타에 캐러셀도 만든다. 브런치에 한국어 롱폼도 쓴다.

문제는, 이걸 16개 채널에서 동시에 하려면 사람이 아니라 조직이 필요하다는 거다.

하나의 소재로 Medium 롱폼을 쓰면 2,000~4,000자. 같은 내용을 LinkedIn에 맞추면 300~800자 인사이트로 압축해야 한다. X 스레드는 280자씩 쪼개야 하고, 인스타 캐러셀은 시각적으로 재구성해야 한다. YouTube 영상은 대본, TTS, 비주얼, 자막까지 전부 다른 작업이다.

매번 이 과정을 수동으로 반복하다 보니, 결국 콘텐츠의 양과 질 사이에서 타협하게 된다. "이번 주는 Medium만 올리자"가 되고, 나머지 채널은 조용해진다.

그래서 직접 만들기로 했다. AI 에이전트가 이 모든 걸 해주는 시스템을.

---

## 처음부터 "플랫폼"으로 접근한 이유

보통 이런 프로젝트를 시작하면 스크립트 하나로 시작한다. "Claude API 호출해서 Medium 글 → LinkedIn 요약 변환하는 스크립트 만들자." 나도 처음엔 그렇게 생각했다.

그런데 채널이 16개다. 파이프라인이 텍스트만 있는 게 아니라 영상, 숏폼, 인포그래픽, 웹툰까지 있다. 스크립트 하나가 아니라, 각각의 전문성을 가진 에이전트들이 협업하는 구조가 필요했다.

결정적으로 생각을 바꾼 건 "피드백 루프"였다. 콘텐츠를 발행하고 끝이 아니라, 성과를 측정하고, 다음 콘텐츠에 반영해야 한다. 어떤 제목이 클릭률이 높았는지, 어떤 포맷이 참여도가 좋았는지. 이걸 시스템이 스스로 학습하려면 스크립트로는 한계가 있다.

그래서 처음부터 모노레포 구조의 플랫폼으로 잡았다. 10개 패키지, 각각 독립적으로 빌드하고 테스트할 수 있는 구조. 이 결정이 나중에 엄청난 차이를 만들었다.

---

## 아키텍처: 사람이 일하는 방식을 그대로

ContentForge의 구조는 실제 콘텐츠 팀이 일하는 방식을 모방했다.

**수집팀** (8개 소스) → **전략 디렉터** (소재 선별) → **전문 파이프라인** (6종) → **휴먼 필터** (자연스러움) → **품질 검수** (팩트체크) → **발행** (16채널) → **분석** (BML 피드백)

이걸 코드로 옮기면 10개의 AI 에이전트가 된다.

```
수집 에이전트     — RSS, 트렌드, 북마크 등 8개 소스에서 소재를 모은다
전략 디렉터      — 어떤 소재를 어떤 파이프라인으로 보낼지 판단한다
트렌드 리서처    — 키워드 리서치, 경쟁 분석을 한다
콘텐츠 라이터    — 채널별 포맷에 맞게 글을 쓴다
비주얼 디렉터    — SVG 인포그래픽, 다이어그램을 만든다
영상 프로듀서    — TTS, 아바타, Remotion 렌더링을 오케스트레이션한다
휴먼라이크 필터  — "AI가 쓴 느낌"을 제거한다
브랜드 가디언    — 톤 일관성, 팩트 체크를 한다
퍼블리셔        — 16개 채널에 자동 발행한다
애널리스트      — 성과를 수집하고 다음 전략을 제안한다
```

각 에이전트는 `BaseAgent`를 상속받는 독립 클래스다. 자기 일만 하고, 결과를 다음 에이전트에게 넘긴다. 에이전트 간 결합도를 낮추니, 하나를 고쳐도 다른 곳이 안 깨진다.

---

## 기술 결정들: 왜 이렇게 했나

### Result<T, E> 패턴 — throw를 버리다

가장 먼저 내린 결정이자, 프로젝트 전체를 관통하는 원칙이다.

```typescript
// 이렇게 하지 않는다
try {
  const script = await generateScript(material);
  const audio = await generateTTS(script);
} catch (e) {
  // 뭐가 실패한 건지 알 수 없다
}

// 이렇게 한다
const scriptResult = await generateScript(material);
if (!scriptResult.isOk) return Err(scriptResult.error);

const audioResult = await generateTTS(scriptResult.value);
if (!audioResult.isOk) return Err(audioResult.error);
```

AI API를 호출하면 실패가 일상이다. 네트워크 에러, Rate limit, 잘못된 응답 포맷. `try-catch`로 감싸면 어디서 뭐가 터졌는지 추적하기 어렵다. `Result` 패턴은 에러를 값으로 다룬다. 모든 실패는 명시적으로 처리되고, 에러 경로가 코드에 그대로 보인다.

10개 에이전트가 체인으로 연결되는 시스템에서, 3번째 에이전트가 실패했을 때 1번째 에이전트까지 에러가 깔끔하게 전파되는 건 이 패턴 덕분이다.

### Zod 스키마 — Claude를 신뢰하지 않는다

Claude API에게 JSON을 달라고 하면, 대부분 잘 준다. 하지만 "대부분"은 "항상"이 아니다.

```typescript
// 위험하다
const script = JSON.parse(response) as VideoScript;

// 안전하다
const parsed = VideoScriptSchema.safeParse(JSON.parse(response));
if (!parsed.success) {
  return Err(`Script validation failed: ${parsed.error.issues}`);
}
```

처음에는 `JSON.parse()` + TypeScript 타입 단언으로 했다. 한 달쯤 지나서 Claude가 `scenes` 배열 대신 `scene` (단수)를 반환한 적이 있다. 런타임에서 `undefined is not iterable` 에러가 터졌다. Zod를 도입한 건 그 이후다.

지금은 모든 Claude API 응답이 Zod 스키마를 통과해야 한다. 파이프라인, 분석, 프롬프트 진화 — 예외 없이. 스키마가 실패하면 에러 경로를 타고, 어떤 필드가 기대와 달랐는지 정확히 알 수 있다.

### 채널 스키마 정규화 — 이름 하나로 삽질한 이야기

16개 채널의 이름이 코드베이스 전체에 흩어져 있다. TypeScript에서는 `ig-carousel`이고, 데이터베이스에서는 `ig_carousel`이다. 레거시 코드에는 `instagram-carousel`이라고 쓴 곳도 있다.

이게 왜 문제냐면, 파이프라인이 `ig-carousel`로 결과를 만들었는데, 퍼블리셔가 `ig_carousel`을 기대하면 매칭이 안 된다. 조용히 실패한다.

결국 정규(canonical) 채널 스키마를 만들었다.

```typescript
// 어디서 들어오든 정규화한다
const channel = normalizeChannel('instagram-carousel'); // → 'ig-carousel'
const dbColumn = channelToDb('ig-carousel');            // → 'ig_carousel'
```

16개 채널, 8개 레거시 별칭, 4개의 DB 매핑. 이걸 한 파일(`channel-schema.ts`)에 모으고, 외부 입력은 반드시 `normalizeChannel()`을 거치게 했다. 단순하지만, 이 패턴 하나로 채널 관련 버그가 사라졌다.

---

## 영상 파이프라인: 가장 어려웠던 결정

텍스트 변환은 비교적 단순하다. Claude에게 "이 소재를 LinkedIn 형식으로 바꿔줘"라고 하면 된다. 하지만 영상은 다르다.

대본 생성 → TTS 음성 → 비주얼 생성 → 아바타 립싱크 → 전부 합성 → MP4 렌더링.

이걸 어떻게 구현할지 네 가지 옵션을 검토했다.

- **Option A**: Claude에게 Remotion TSX 코드 자체를 생성하게 한다 → 보안 위험, 빌드 불안정
- **Option B**: HTML을 렌더링해서 Puppeteer로 프레임 캡처 → 품질 열악
- **Option C**: 프리셋 템플릿만 사용 → 창의성 제로
- **Option D**: 템플릿 + Claude SVG 주입 하이브리드 → 안정성과 창의성 균형

Option D를 선택했다. 기본 씬 레이아웃은 12개의 Remotion 템플릿이 보장하고, 복잡한 시각화(다이어그램, 차트, 타임라인)는 Claude가 SVG로 생성한다.

단, Claude가 생성한 SVG를 그대로 `dangerouslySetInnerHTML`에 넣으면 XSS 공격 벡터가 된다. 그래서 SVG 새니타이저를 직접 만들었다. `<script>`, `<foreignObject>`, `<iframe>` 차단. `on*` 이벤트 핸들러 제거. `javascript:` URI 차단. 이건 보안 크리티컬이라 회귀 테스트도 별도로 돌린다.

에디터는 Vue 3로 만들었다. Remotion은 React 기반이지만, 서버 렌더링(MP4 생성)에만 쓰고, 에디터 UI는 Vue로 완전히 분리했다. 미리보기는 iframe에 HTML/CSS/SVG를 직접 렌더링한다. 최종 품질은 서버의 Remotion이 보장하니까, 미리보기는 "근사치"로 충분하다.

---

## Claude Code와 함께 만든다는 것

솔직히 말하면, 이 프로젝트의 코드 대부분은 Claude Code가 작성했다. 나의 역할은 아키텍트이자 프로덕트 매니저에 가깝다. 무엇을 만들지 결정하고, 어떤 구조로 만들지 설계하고, 결과물의 품질을 검증한다.

이 과정에서 배운 것들이 있다.

### 1. "무엇을"보다 "어떻게"를 먼저 정의해라

Claude Code에게 "Medium 퍼블리셔 만들어줘"라고 하면 만들어준다. 하지만 프로젝트 전체와 일관된 패턴으로 만들어주진 않는다.

그래서 먼저 만든 것들이 있다.
- `BaseAgent`, `BasePipeline`, `BasePublisher` 추상 클래스
- `Result<T, E>` 패턴 유틸리티
- 채널 스키마, 로깅 유틸리티 같은 공유 인프라

이 "뼈대"를 먼저 잡아놓으면, 이후에 에이전트든 파이프라인이든 "이 패턴을 따라서 만들어줘"라고 할 수 있다. 일관성이 자동으로 확보된다.

### 2. CLAUDE.md가 진짜 중요하다

프로젝트 루트의 `CLAUDE.md`와 각 패키지의 `CLAUDE.md`에 규칙을 적어놓으면, Claude Code가 매번 참조한다.

```
- Result<T, E> 패턴의 unwrap()은 테스트/CLI 전용. 비즈니스 로직에서 사용 금지
- 모든 채널 참조는 canonical 형식 사용
- Claude API 응답은 반드시 Zod 스키마로 검증
```

이런 원칙을 문서화하지 않으면, 같은 실수가 반복된다. CLAUDE.md는 코드베이스의 "기억"이다. 사람이 온보딩 문서를 읽듯이, AI도 이 문서를 읽고 맥락을 파악한다.

### 3. 에이전트 정의 파일로 전문성을 분리한다

`.claude/agents/` 디렉토리에 8개의 에이전트 정의 파일이 있다. 백엔드 엔지니어, 비디오 엔지니어, 프론트엔드 엔지니어, AI 엔지니어 등. 각각 담당 패키지, 따라야 할 패턴, 참고 파일이 적혀있다.

이건 단순한 문서가 아니다. Claude Code가 특정 작업을 할 때, 해당 에이전트의 맥락을 로드해서 전문성 있는 코드를 생성할 수 있게 해준다. "비디오 엔지니어"로 작업하면 SVG 보안 규칙을 자동으로 따르고, "프론트엔드 엔지니어"로 작업하면 Style L 디자인 시스템을 따른다.

### 4. 테스트가 신뢰의 근거다

AI가 작성한 코드를 어떻게 신뢰할까? 테스트다.

현재 전체 테스트 수는 약 600개. 10개 패키지가 모두 빌드되고 테스트를 통과해야 한다. 새 기능을 추가할 때마다 관련 테스트가 함께 작성되고, 전체 빌드가 깨지지 않는지 확인한다.

Claude Code가 코드를 작성하면, 내가 하는 일은 테스트를 돌리는 것이다. 20/20 패스가 뜨면 머지한다. 실패하면 고친다. 이 사이클이 반복되면서, 코드베이스의 신뢰도가 쌓인다.

---

## 페이즈별 개발: 점진적 복잡성 확장

한 번에 다 만들지 않았다. 4개 페이즈로 나눠서 점진적으로 확장했다.

**Phase 1** (텍스트 MVP): 모노레포 셋업 → 수집기 3개 → 텍스트 파이프라인 → Medium/LinkedIn/X 퍼블리셔 → CLI. 이게 되면 "소재를 넣으면 3개 채널 글이 나온다"는 핵심 가치가 증명된다.

**Phase 2** (채널 확장): 퍼블리셔 5개 추가 → 스낵커블 파이프라인 (인스타) → BML 측정 시작. 채널이 늘어나도 같은 패턴으로 확장할 수 있다는 걸 증명한다.

**Phase 3** (영상): 가장 복잡한 구간. Remotion 서버 렌더러 → SVG 새니타이저 → 12개 씬 컴포넌트 → AI 아바타 → Vue 에디터 → 7개 비주얼 소스 → 숏폼 파이프라인 → BML 학습 루프.

**Phase 4** (완성도): 웹툰 파이프라인 → 풀 자동화(n8n) → 운영 안정화(Sentry, Langfuse) → 에디터 고도화(대시보드, 협업, 마켓플레이스).

각 페이즈가 끝날 때마다 전체 빌드와 테스트를 돌렸다. "이전에 만든 게 안 깨지는지"를 확인하는 게 다음 페이즈로 넘어가는 조건이었다.

---

## Build-Measure-Learn: 시스템이 스스로 학습한다

가장 흥미로운 부분은 BML 피드백 루프다.

콘텐츠를 발행하면, 48시간 후에 초기 반응을 분석한다. 조회수, 참여도, 클릭률. 이 데이터가 쌓이면 주간 루프가 돌면서 "이번 주는 이런 패턴이 잘 먹혔다"는 인사이트를 뽑는다.

더 재밌는 건 프롬프트 진화(Prompt Evolution)다. 고성과 콘텐츠에서 공통 패턴을 추출하고, 이걸 에이전트의 프롬프트에 반영한다. "데이터로 시작하는 도입부가 참여도가 23% 높았다"는 인사이트가 나오면, 다음부터 콘텐츠 라이터 에이전트의 프롬프트에 이 패턴이 반영된다.

시스템이 쓸수록 똑똑해지는 구조. 이게 단순 자동화와 플랫폼의 차이다.

---

## 모노레포의 힘

솔직히, 초기에 모노레포 셋업하느라 시간이 좀 걸렸다. Turborepo + pnpm 설정, 10개 패키지의 tsconfig 연결, 빌드 순서 관리. "그냥 하나의 프로젝트로 만들면 안 되나?"라는 유혹이 있었다.

하지만 패키지가 10개로 늘어난 지금, 모노레포를 선택한 게 정말 잘한 결정이었다.

- **독립 빌드/테스트**: `pnpm --filter @content-forge/video test`로 비디오 패키지만 테스트할 수 있다. 전체 빌드를 안 돌려도 된다.
- **의존성 명시**: `core` → `agents` → `pipelines` → `publishers` 순서가 코드에 강제된다. 순환 의존이 구조적으로 불가능하다.
- **병렬 작업**: 서로 다른 패키지를 동시에 작업할 수 있다. 비디오 엔지니어가 Remotion 씬을 만드는 동안 백엔드 엔지니어가 퍼블리셔를 만들 수 있다.

Turborepo의 빌드 캐싱도 빛을 발한다. 변경이 없는 패키지는 빌드를 건너뛴다. 10개 패키지 중 하나만 고쳤을 때, 전체 빌드 시간이 수십 초에서 몇 초로 줄어든다.

---

## 남은 이야기들

아직 갈 길이 남아있다. Supabase 실제 연동, Express/Fastify 백엔드 API, Redis 어댑터 교체, 실제 채널 API 키 연결. 지금은 모든 외부 의존성이 모킹되어 있다.

하지만 핵심은 이미 작동한다. 소재를 넣으면 16개 채널에 맞는 콘텐츠가 나온다. 영상 스크립트가 생성되고, SVG 비주얼이 만들어지고, TTS 음성이 합성된다. 에디터에서 씬을 편집하고, 렌더링 버튼을 누르면 MP4가 나온다.

1인 크리에이터가 16개 채널을 운영할 수 있게 해주는 시스템. 그게 ContentForge가 풀려는 문제이고, AI 에이전트가 그 해법의 핵심이다.

---

## 요약: 이 프로젝트에서 배운 것

1. **추상화를 먼저 설계하라** — BaseAgent, BasePipeline, Result 패턴. 뼈대가 있으면 확장은 자연스럽다.
2. **AI 출력을 신뢰하지 마라** — Zod 스키마로 모든 AI 응답을 검증한다. "대부분 맞다"는 프로덕션에서 통하지 않는다.
3. **이름을 정규화하라** — 채널 16개, 별칭 8개, DB 매핑 4개. 하나의 진실의 원천(Single Source of Truth)이 필요하다.
4. **모노레포는 초기 투자, 장기 이득이다** — 독립 빌드, 명시적 의존성, 병렬 작업. 패키지가 5개를 넘는 순간 본전을 뽑는다.
5. **CLAUDE.md는 AI와의 계약서다** — 규칙을 문서화하면 AI가 일관된 코드를 생성한다. 문서화하지 않으면 매번 같은 실수가 반복된다.
6. **테스트가 신뢰의 근거다** — AI가 작성한 600개의 테스트가, AI가 작성한 코드의 정확성을 증명한다. 이 루프가 전부다.
7. **피드백 루프를 설계에 포함하라** — BML은 나중에 추가하는 게 아니라, 아키텍처에 내장한다. 시스템이 학습하지 않으면 도구일 뿐이다.

---

*ContentForge는 현재 개발 단계이며, 오픈소스 공개를 준비 중입니다.*

*이 글에 대한 피드백이나 질문은 언제든 환영합니다.*
